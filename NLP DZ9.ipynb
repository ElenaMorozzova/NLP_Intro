{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP DZ9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNAJiYZ00KTR0T7tW8Qkaib",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElenaMorozzova/NLP_Intro/blob/main/NLP%20DZ9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrH0C93g6uhY",
        "outputId": "c2ab8292-65b6-4d7f-baf7-04c3334eb1f7"
      },
      "source": [
        "!pip install pymorphy2\n",
        "!pip install stop_words\n",
        "\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 9.0 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
            "Collecting stop_words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32912 sha256=59cfcf192848d37da020671919e8148c4c80aefdb64b1e419af58ff7ae070e31\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "fzEKKRJPDVs1",
        "outputId": "079d1d02-8238-47b5-8922-ded57398c88f"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f169a45a-3bc4-4901-873f-bcd02fb86879\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f169a45a-3bc4-4901-873f-bcd02fb86879\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving eminem_lyrics.txt to eminem_lyrics.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owdefQrMeQlX"
      },
      "source": [
        "**Load and preprocess text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Ye7qISEio4",
        "outputId": "9163a7cb-4600-4720-b61a-fc12907b84a8"
      },
      "source": [
        "text = open('eminem_lyrics.txt', 'r').read()\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 439328 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cR8tMh-DsaZ",
        "outputId": "2d100d68-01fb-4212-d56c-c278c2d5fa9c"
      },
      "source": [
        "text = text.split('\\n\\n')\n",
        "text[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"Walk On Water\"\\n(feat. Beyoncé)',\n",
              " \"[Beyoncé (Eminem):]\\nI walk on water\\nBut I ain't no Jesus\\nI walk on water\\nBut only when it freezes (fuck)\",\n",
              " \"[Eminem:]\\nWhy are expectations so high?\\nIs it the bar I set?\\nMy arms, I stretch, but I can't reach\\nA far cry from it, or it's in my grasp, but as\\nSoon as I grab, squeeze\\nI lose my grip like the flyin' trapeze\\nInto the dark I plummet, now the sky's blackenin'\\nI know the mark's high, butterflies rip apart my stomach\\nKnowin' that no matter what bars I come with\\nYou're gonna harp, gripe, and\\nThat's a hard Vicodin to swallow, so I scrap these\\nAs pressure increases like khakis\\nI feel the ice cracking, because\",\n",
              " \"[Beyoncé (Eminem):]\\nI walk on water\\nBut I ain't no Jesus\\n(It's the curse of the, it's the curse of the)\\nI walk on water (shit)\\nBut only when it freezes\",\n",
              " '[Eminem:]\\nIt\\'s the curse of the standard, that the first of the Mathers disc set\\nAlways in search of the verse that I haven\\'t spit yet\\nWill this step just be another misstep\\nTo tarnish, whatever the legacy, love or respect\\nI\\'ve garnered?\\nThe rhyme has to be perfect, the delivery flawless\\nAnd it always feels like I\\'m hittin\\' the mark\\n\\'Til I go sit in the car, listen and pick it apart\\nLike, \"This shit is garbage!\"\\nGod\\'s given me all this, still I feel no different regardless\\nKids look to me as a god, this is retarded\\nIf only they knew, it\\'s a facade and it\\'s exhaustive\\nAnd I try not to listen to nonsense\\nBut if you bitches are tryin\\' to strip me of my confidence\\nMission accomplished\\nI\\'m not God-sent\\nNas, Rakim, Pac, B.I.G., James Todd Smith, and I\\'m not Prince, so']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFRVwi0fDslz",
        "outputId": "bb492f4b-0edd-4208-b98f-93b3cd1f339c"
      },
      "source": [
        "text_only = []\n",
        "for strofa in text:\n",
        "    if len(strofa) < 350:\n",
        "        continue\n",
        "    else:\n",
        "        text_only.append(strofa)\n",
        "len(text_only)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "356"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WRo2J7BDsos",
        "outputId": "32fab766-4dcf-4b7c-d508-299d934ba95d"
      },
      "source": [
        "text_only[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"[Eminem:]\\nWhy are expectations so high?\\nIs it the bar I set?\\nMy arms, I stretch, but I can't reach\\nA far cry from it, or it's in my grasp, but as\\nSoon as I grab, squeeze\\nI lose my grip like the flyin' trapeze\\nInto the dark I plummet, now the sky's blackenin'\\nI know the mark's high, butterflies rip apart my stomach\\nKnowin' that no matter what bars I come with\\nYou're gonna harp, gripe, and\\nThat's a hard Vicodin to swallow, so I scrap these\\nAs pressure increases like khakis\\nI feel the ice cracking, because\",\n",
              " '[Eminem:]\\nIt\\'s the curse of the standard, that the first of the Mathers disc set\\nAlways in search of the verse that I haven\\'t spit yet\\nWill this step just be another misstep\\nTo tarnish, whatever the legacy, love or respect\\nI\\'ve garnered?\\nThe rhyme has to be perfect, the delivery flawless\\nAnd it always feels like I\\'m hittin\\' the mark\\n\\'Til I go sit in the car, listen and pick it apart\\nLike, \"This shit is garbage!\"\\nGod\\'s given me all this, still I feel no different regardless\\nKids look to me as a god, this is retarded\\nIf only they knew, it\\'s a facade and it\\'s exhaustive\\nAnd I try not to listen to nonsense\\nBut if you bitches are tryin\\' to strip me of my confidence\\nMission accomplished\\nI\\'m not God-sent\\nNas, Rakim, Pac, B.I.G., James Todd Smith, and I\\'m not Prince, so',\n",
              " '[Eminem:]\\nIt\\'s true, I\\'m a Rubik\\'s, a beautiful mess\\nAt times juvenile, yes, I goof and I jest\\nA flawed human, I guess\\nBut I\\'m doin\\' my best to not ruin your expectations and meet \\'em, but first\\nThe \"Speedom\" verse, now Big Sean\\nHe\\'s going too fast, is he gonna shout or curse out his mom?\\nThere was a time I had the world by the balls, eating out my palm\\nEvery album song I was spazzin\\' the fuck out on\\nAnd now I\\'m gettin\\' clowned and frowned on\\nBut the only one who\\'s looking down on\\nMe that matters now\\'s DeShaun\\nAm I lucky to be around this long?\\nBegs the question though\\nEspecially after the methadone\\nAs yesterday fades and the Dresden home\\nIs burnt to the ground, and all that\\'s left of my house is lawn\\nThe crowds are gone\\nAnd it\\'s time to wash out the blonde\\nSales decline, the curtains drawn\\nThey\\'re closing the set, I\\'m still poking my head from out behind\\nAnd everyone who has doubt, remind\\nNow take your best rhyme, outdo it, now do it a thousand times\\nNow let \\'em tell ya the world no longer cares or gives a fuck about your rhymes\\nAnd as I grow outta sight, outta mind, I might go outta mine\\n\\'Cause how do I ever let this mic go without a fight\\nWhen I made a fuckin\\' tightrope outta twine?\\nBut when I do fall from these heights though, I\\'ll be fine\\nI won\\'t pout or cry or spiral down or whine\\nBut I\\'ll decide if it\\'s my final bow this time around, \\'cause',\n",
              " \"I want you to understand something\\nThat when I come up in this bitch, I want the fans jumping\\nI want the fists pumping in the air, I don't look like a millionaire\\nBut I feel like a million bucks, ladies won't ya fill your cups?\\nShady's come to feel ya up, are you a D or a C cup?\\nYou could even be a B, it's just me and D-R-E\\nYou'll be in the ER, we are strapped with so much TNT\\nWe may blow, no, not even CPR from the EMTs\\nCould help you to resuscitate, you busters must be flustered, wait\\nYou can't cut the mustard\\nWhat's your problem, can't you bust a grape?\\n(Chkk-chk-chk) What's my name?\\nShady came and just crushed the game\\nIt's really not even fair to them\\n'Cause they pale in comparison\\nSo much they might as well wear his skin\\nDon't you wish you could just share his pen?\\n'Cause this shit's getting embarrassin'\\nThe fog is thick and the air is thin\\n'Cause he won't even let them try to breathe\\nLa-dididi-dadada-didi\\nHe makes it look so easy, girl, you just hit the lottery\",\n",
              " \"This is when shit hits the fan like it just splattered on Stan\\nThis is the only moment that matters\\nYour homie rolled in with Mathers\\nNow chaos erupts, Em's in back, Dre's in the front\\nSo do what we say at once, this song’s like a seance, it haunts\\nIt makes them stay in a trance, no choice, they have to dance\\nIt's like the playoffs, just making sure that we stay in the hunt\\nTake a day off of what? Man, you better lay off the blunts\\nYou must be smoking something\\nYou think I ain't smoking nothing, stay off my nuts\\nNow hit the floor, baby, time to wipe away all the rust\\nShake all them cobwebs loose\\nLoosen up with a little bit of Grey Goose\\nYeah, girl, shake that caboose\\nI don't wanna see you try to make no excuse\\nD-R-E is on the loose\\nA mongoose when it comes to the chronic use\\nYou know I can't stand to lose\\nMe and my goons are like animals\\nWe come through like a pack of wolves\\nAnd we came here to retract the roof\\nYeah, man, ain't that the truth\\nGirl, your man's back in the booth\\nDefinitely back up in this bitch\\nAnd this is when all hell breaks loose\"]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hTt-AgZeDsrv",
        "outputId": "404a9602-ba28-433d-8117-4bae60cbeabe"
      },
      "source": [
        "data = pd.DataFrame(text_only)\n",
        "data = data.rename(columns={0: \"Content\"})\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Eminem:]\\nWhy are expectations so high?\\nIs i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Eminem:]\\nIt's the curse of the standard, tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Eminem:]\\nIt's true, I'm a Rubik's, a beautif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I want you to understand something\\nThat when ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This is when shit hits the fan like it just sp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>Some boys are wiling\\nDrinkin', cussin', and h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>Yeah this game has got me goin' crazy\\nFuck it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>Got a dick as big as a banana\\nI try to contro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>Are you ready? You better hold the camera stea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>It's eerie, but here comes Zack and Miri\\nBeau...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>356 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Content\n",
              "0    [Eminem:]\\nWhy are expectations so high?\\nIs i...\n",
              "1    [Eminem:]\\nIt's the curse of the standard, tha...\n",
              "2    [Eminem:]\\nIt's true, I'm a Rubik's, a beautif...\n",
              "3    I want you to understand something\\nThat when ...\n",
              "4    This is when shit hits the fan like it just sp...\n",
              "..                                                 ...\n",
              "351  Some boys are wiling\\nDrinkin', cussin', and h...\n",
              "352  Yeah this game has got me goin' crazy\\nFuck it...\n",
              "353  Got a dick as big as a banana\\nI try to contro...\n",
              "354  Are you ready? You better hold the camera stea...\n",
              "355  It's eerie, but here comes Zack and Miri\\nBeau...\n",
              "\n",
              "[356 rows x 1 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_Dv6uFs-GTjQ",
        "outputId": "7cfa3477-ac0f-4d9c-feb6-6cb1a10b9afa"
      },
      "source": [
        "sw = set(get_stop_words(\"en\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def exclude_punctuation(txt):\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)    \n",
        "    txt = re.sub(\"\\n\", \" \\n\", txt)    \n",
        "    return txt\n",
        "\n",
        "def preprocess_text(txt, morph = False):\n",
        "    txt = str(txt)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\n\", \"zzz\", txt)\n",
        "    new_txt =[]\n",
        "    for word in txt.split():\n",
        "        if word == \"zzz\":\n",
        "            word = \" \\n\"\n",
        "            \n",
        "        else:\n",
        "            if morph:\n",
        "                word = morpher.parse(word)[0].normal_form\n",
        "            else:\n",
        "                pass\n",
        "        new_txt.append(word)\n",
        "\n",
        "    return new_txt\n",
        "\n",
        "data['Content_splited'] = data['Content'].apply(exclude_punctuation)\n",
        "data['Content_splited_morph'] = data['Content_splited'].apply(preprocess_text, morph = True)\n",
        "data['Content_splited'] = data['Content_splited'].apply(preprocess_text, morph = False)\n",
        "\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>Content_splited</th>\n",
              "      <th>Content_splited_morph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Eminem:]\\nWhy are expectations so high?\\nIs i...</td>\n",
              "      <td>[eminem, zzzwhy, are, expectations, so, high, ...</td>\n",
              "      <td>[eminem, zzzwhy, are, expectations, so, high, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Eminem:]\\nIt's the curse of the standard, tha...</td>\n",
              "      <td>[eminem, zzzits, the, curse, of, the, standard...</td>\n",
              "      <td>[eminem, zzzits, the, curse, of, the, standard...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Eminem:]\\nIt's true, I'm a Rubik's, a beautif...</td>\n",
              "      <td>[eminem, zzzits, true, im, a, rubiks, a, beaut...</td>\n",
              "      <td>[eminem, zzzits, true, im, a, rubiks, a, beaut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I want you to understand something\\nThat when ...</td>\n",
              "      <td>[i, want, you, to, understand, something, zzzt...</td>\n",
              "      <td>[i, want, you, to, understand, something, zzzt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This is when shit hits the fan like it just sp...</td>\n",
              "      <td>[this, is, when, shit, hits, the, fan, like, i...</td>\n",
              "      <td>[this, is, when, shit, hits, the, fan, like, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Now I know you're feeling discouraged\\nBut, ho...</td>\n",
              "      <td>[now, i, know, youre, feeling, discouraged, zz...</td>\n",
              "      <td>[now, i, know, youre, feeling, discouraged, zz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Yeah, so let us in 'fore we huff and puff and ...</td>\n",
              "      <td>[yeah, so, let, us, in, fore, we, huff, and, p...</td>\n",
              "      <td>[yeah, so, let, us, in, fore, we, huff, and, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>If I was frozen inside of a moment\\nIf I could...</td>\n",
              "      <td>[if, i, was, frozen, inside, of, a, moment, zz...</td>\n",
              "      <td>[if, i, was, frozen, inside, of, a, moment, zz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Lose yourself in this music\\nThis moment we ow...</td>\n",
              "      <td>[lose, yourself, in, this, music, zzzthis, mom...</td>\n",
              "      <td>[lose, yourself, in, this, music, zzzthis, mom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Cause when we descend together, we begin to mo...</td>\n",
              "      <td>[cause, when, we, descend, together, we, begin...</td>\n",
              "      <td>[cause, when, we, descend, together, we, begin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Content  ...                              Content_splited_morph\n",
              "0  [Eminem:]\\nWhy are expectations so high?\\nIs i...  ...  [eminem, zzzwhy, are, expectations, so, high, ...\n",
              "1  [Eminem:]\\nIt's the curse of the standard, tha...  ...  [eminem, zzzits, the, curse, of, the, standard...\n",
              "2  [Eminem:]\\nIt's true, I'm a Rubik's, a beautif...  ...  [eminem, zzzits, true, im, a, rubiks, a, beaut...\n",
              "3  I want you to understand something\\nThat when ...  ...  [i, want, you, to, understand, something, zzzt...\n",
              "4  This is when shit hits the fan like it just sp...  ...  [this, is, when, shit, hits, the, fan, like, i...\n",
              "5  Now I know you're feeling discouraged\\nBut, ho...  ...  [now, i, know, youre, feeling, discouraged, zz...\n",
              "6  Yeah, so let us in 'fore we huff and puff and ...  ...  [yeah, so, let, us, in, fore, we, huff, and, p...\n",
              "7  If I was frozen inside of a moment\\nIf I could...  ...  [if, i, was, frozen, inside, of, a, moment, zz...\n",
              "8  Lose yourself in this music\\nThis moment we ow...  ...  [lose, yourself, in, this, music, zzzthis, mom...\n",
              "9  Cause when we descend together, we begin to mo...  ...  [cause, when, we, descend, together, we, begin...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnDuLx7UGTmE"
      },
      "source": [
        "def get_int(column_data):\n",
        "    \n",
        "    dump = list(column_data.values)\n",
        "    dump_txt_split = []\n",
        "    for sublist in dump:\n",
        "        for item in sublist:\n",
        "            dump_txt_split.append(item)\n",
        "\n",
        "\n",
        "    vocab = sorted(set(dump_txt_split))\n",
        "    print('{} unique characters'.format(len(vocab)))            \n",
        "            \n",
        "    # Creating a mapping from unique characters to indices\n",
        "    char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "    idx2char = np.array(vocab)\n",
        "    \n",
        "    print(len(vocab), len(char2idx), len(idx2char))\n",
        "    return char2idx, idx2char, vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UtfC-4sGTpJ",
        "outputId": "3b711cf3-80da-41dc-fc41-52de557a7ea0"
      },
      "source": [
        "char2idx, idx2char, vocab = get_int(data['Content_splited'])        \n",
        "data['text_as_int'] = data['Content_splited'].apply(lambda x: [char2idx[c] for c in x])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9414 unique characters\n",
            "9414 9414 9414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fM0qL5VfGTu-",
        "outputId": "bb9d9023-b67b-421a-a2f1-e91c1070d764"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>Content_splited</th>\n",
              "      <th>Content_splited_morph</th>\n",
              "      <th>text_as_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Eminem:]\\nWhy are expectations so high?\\nIs i...</td>\n",
              "      <td>[eminem, zzzwhy, are, expectations, so, high, ...</td>\n",
              "      <td>[eminem, zzzwhy, are, expectations, so, high, ...</td>\n",
              "      <td>[2359, 9362, 338, 2486, 6542, 3363, 8670, 3734...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Eminem:]\\nIt's the curse of the standard, tha...</td>\n",
              "      <td>[eminem, zzzits, the, curse, of, the, standard...</td>\n",
              "      <td>[eminem, zzzits, the, curse, of, the, standard...</td>\n",
              "      <td>[2359, 8675, 7176, 1749, 4897, 7176, 6751, 717...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Eminem:]\\nIt's true, I'm a Rubik's, a beautif...</td>\n",
              "      <td>[eminem, zzzits, true, im, a, rubiks, a, beaut...</td>\n",
              "      <td>[eminem, zzzits, true, im, a, rubiks, a, beaut...</td>\n",
              "      <td>[2359, 8675, 7441, 3594, 52, 5952, 52, 596, 44...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I want you to understand something\\nThat when ...</td>\n",
              "      <td>[i, want, you, to, understand, something, zzzt...</td>\n",
              "      <td>[i, want, you, to, understand, something, zzzt...</td>\n",
              "      <td>[3567, 7758, 8080, 7295, 7540, 6578, 9224, 785...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This is when shit hits the fan like it just sp...</td>\n",
              "      <td>[this, is, when, shit, hits, the, fan, like, i...</td>\n",
              "      <td>[this, is, when, shit, hits, the, fan, like, i...</td>\n",
              "      <td>[7212, 3723, 7852, 6276, 3395, 7176, 2580, 412...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Content  ...                                        text_as_int\n",
              "0  [Eminem:]\\nWhy are expectations so high?\\nIs i...  ...  [2359, 9362, 338, 2486, 6542, 3363, 8670, 3734...\n",
              "1  [Eminem:]\\nIt's the curse of the standard, tha...  ...  [2359, 8675, 7176, 1749, 4897, 7176, 6751, 717...\n",
              "2  [Eminem:]\\nIt's true, I'm a Rubik's, a beautif...  ...  [2359, 8675, 7441, 3594, 52, 5952, 52, 596, 44...\n",
              "3  I want you to understand something\\nThat when ...  ...  [3567, 7758, 8080, 7295, 7540, 6578, 9224, 785...\n",
              "4  This is when shit hits the fan like it just sp...  ...  [7212, 3723, 7852, 6276, 3395, 7176, 2580, 412...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slME9BqXGTx0",
        "outputId": "43988c37-14ef-4afa-999b-683a64328dc3"
      },
      "source": [
        "def get_all_int(column_data):\n",
        "    \n",
        "    int_dump = column_data.values\n",
        "    all_txt_as_int = []\n",
        "\n",
        "    for sublist in int_dump:\n",
        "        for item in sublist:\n",
        "            all_txt_as_int.append(item)\n",
        "    all_txt_as_int = np.array(all_txt_as_int)    \n",
        "    \n",
        "    return all_txt_as_int\n",
        "\n",
        "all_txt_as_int = get_all_int(data['text_as_int'])\n",
        "all_txt_as_int"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2359, 9362,  338, ...,  715, 3871, 3042])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXDYb3WOGT01",
        "outputId": "6ab574b8-be15-4127-f0cf-2ee2390efc03"
      },
      "source": [
        "# The maximum length sentence you want for a single input in characters\n",
        "seq_length = 35\n",
        "examples_per_epoch = len(all_txt_as_int)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "word_dataset = tf.data.Dataset.from_tensor_slices(all_txt_as_int)\n",
        "\n",
        "for i in word_dataset.take(15):\n",
        "    print(idx2char[i.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eminem\n",
            "zzzwhy\n",
            "are\n",
            "expectations\n",
            "so\n",
            "high\n",
            "zzzis\n",
            "it\n",
            "the\n",
            "bar\n",
            "i\n",
            "set\n",
            "zzzmy\n",
            "arms\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MtiOOfpGT3u",
        "outputId": "cabe714e-d6ec-44c4-f7ec-4a57d02ade66"
      },
      "source": [
        "sequences = word_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(3):\n",
        "    print(repr(idx2char[item.numpy()]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "array(['eminem', 'zzzwhy', 'are', 'expectations', 'so', 'high', 'zzzis',\n",
            "       'it', 'the', 'bar', 'i', 'set', 'zzzmy', 'arms', 'i', 'stretch',\n",
            "       'but', 'i', 'cant', 'reach', 'zzza', 'far', 'cry', 'from', 'it',\n",
            "       'or', 'its', 'in', 'my', 'grasp', 'but', 'as', 'zzzsoon', 'as',\n",
            "       'i', 'grab'], dtype='<U28')\n",
            "array(['squeeze', 'zzzi', 'lose', 'my', 'grip', 'like', 'the', 'flyin',\n",
            "       'trapeze', 'zzzinto', 'the', 'dark', 'i', 'plummet', 'now', 'the',\n",
            "       'skys', 'blackenin', 'zzzi', 'know', 'the', 'marks', 'high',\n",
            "       'butterflies', 'rip', 'apart', 'my', 'stomach', 'zzzknowin',\n",
            "       'that', 'no', 'matter', 'what', 'bars', 'i', 'come'], dtype='<U28')\n",
            "array(['with', 'zzzyoure', 'gonna', 'harp', 'gripe', 'and', 'zzzthats',\n",
            "       'a', 'hard', 'vicodin', 'to', 'swallow', 'so', 'i', 'scrap',\n",
            "       'these', 'zzzas', 'pressure', 'increases', 'like', 'khakis',\n",
            "       'zzzi', 'feel', 'the', 'ice', 'cracking', 'because', 'eminem',\n",
            "       'zzzits', 'the', 'curse', 'of', 'the', 'standard', 'that', 'the'],\n",
            "      dtype='<U28')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNmyk_ulG4Mk"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EppMz4EnHAQV",
        "outputId": "0c357c41-64fc-47b0-ca59-b33fc3f03589"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(' '.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(' '.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input data:  'eminem zzzwhy are expectations so high zzzis it the bar i set zzzmy arms i stretch but i cant reach zzza far cry from it or its in my grasp but as zzzsoon as i'\n",
            "Target data: 'zzzwhy are expectations so high zzzis it the bar i set zzzmy arms i stretch but i cant reach zzza far cry from it or its in my grasp but as zzzsoon as i grab'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1PR2ZO-eYsm"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rh0kw3jHCDa",
        "outputId": "c8a74377-1c27-4dbb-9cf3-d1ec08a2dc44"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((256, 35), (256, 35)), types: (tf.int64, tf.int64)>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLNKU7a1HO88"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXQontjodN5E"
      },
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "        tf.keras.layers.LSTM(rnn_units, return_sequences=True),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F1FyfW5dRFu"
      },
      "source": [
        "class RNNgenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, batch_size):\n",
        "        super(RNNgenerator, self).__init__()\n",
        "        \n",
        "        self.emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "                                 \n",
        "        self.gru1 = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform')\n",
        "        self.gru2 = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform')\n",
        "                           \n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x):\n",
        "        emb_x = self.emb(x)\n",
        "        x1 = self.gru1(emb_x)\n",
        "        x = x1\n",
        "        for _ in range(3):\n",
        "            x = self.gru2(x)\n",
        "        #x = self.gru1(x)\n",
        "        x = (x + x1)/2\n",
        "        return self.fc(x)\n",
        "\n",
        "model = RNNgenerator(vocab_size, embedding_dim, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9w4Zt2jdRIl"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "                                 \n",
        "        tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=False,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=False,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "         tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=False,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "                                   \n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLRSafKhdRLw"
      },
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0mO6lxuHTHV"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        " \n",
        "    inputs = tf.keras.layers.Input(batch_input_shape=[batch_size, None])\n",
        "\n",
        "    x =     tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "    print(x.shape)\n",
        "    x1 = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform')(x)\n",
        "    x = tf.keras.layers.concatenate([x,x1], axis=-1)\n",
        "    \n",
        "    print(x.shape)\n",
        "    x2 = tf.keras.layers.GRU(rnn_units+embedding_dim,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform')(x)\n",
        "    x = tf.keras.layers.add([x,x2])\n",
        "    \n",
        "    print(x.shape)\n",
        "    x3 = tf.keras.layers.GRU(rnn_units+embedding_dim,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform')(x)   \n",
        "    \n",
        "    x = tf.keras.layers.add([x,x3])   \n",
        "    x = tf.keras.layers.Dense(vocab_size)(x)\n",
        "    print(x.shape)\n",
        "\n",
        "    model =tf.keras. Model(inputs=inputs, outputs=x)\n",
        "    \n",
        "        \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbUCFK8Mdo6V",
        "outputId": "7fea54f4-6a21-4a8f-b827-b7fa85227633"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(256, 35, 9414) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czWnd69Vdo8s",
        "outputId": "a2b36067-cd7d-4e54-a545-f2e019311336"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 256)         2409984   \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, None, 1024)        3938304   \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, None, 1024)        6297600   \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (None, None, 1024)        6297600   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, None, 9414)        9649350   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,592,838\n",
            "Trainable params: 28,592,838\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utV3KW_pdo_p",
        "outputId": "d1e65d63-0e7f-4e73-c819-4832554fc6d7"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (256, 35, 9414)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       9.14996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkf2yrD_dx_t"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDdPN9xreiqQ"
      },
      "source": [
        "**Set checkpoints and train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx0w7OUNHZ23"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_freq=20,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DjbH7VVHZ5u"
      },
      "source": [
        "EPOCHS = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gdPEGWBHZ8o",
        "outputId": "e58f231d-d93f-490b-e17e-147ab81a7639"
      },
      "source": [
        "for i in range(EPOCHS):\n",
        "    model.fit(dataset, epochs=1, callbacks=[checkpoint_callback])\n",
        "    #model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
        "    model.reset_states()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 212s 30s/step - loss: 8.4674\n",
            "7/7 [==============================] - 207s 29s/step - loss: 7.2429\n",
            "7/7 [==============================] - 210s 30s/step - loss: 7.0826\n",
            "7/7 [==============================] - 206s 29s/step - loss: 7.0036\n",
            "7/7 [==============================] - 205s 29s/step - loss: 6.9817\n",
            "7/7 [==============================] - 212s 30s/step - loss: 6.9699\n",
            "7/7 [==============================] - 207s 30s/step - loss: 6.9670\n",
            "7/7 [==============================] - 208s 30s/step - loss: 6.9510\n",
            "7/7 [==============================] - 213s 31s/step - loss: 6.9532\n",
            "7/7 [==============================] - 208s 30s/step - loss: 6.9542\n",
            "7/7 [==============================] - 209s 30s/step - loss: 6.9407\n",
            "7/7 [==============================] - 213s 30s/step - loss: 6.9400\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.9440\n",
            "7/7 [==============================] - 207s 29s/step - loss: 6.9348\n",
            "7/7 [==============================] - 211s 30s/step - loss: 6.9342\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.9299\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.9298\n",
            "7/7 [==============================] - 210s 29s/step - loss: 6.9253\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.9200\n",
            "7/7 [==============================] - 211s 30s/step - loss: 6.9219\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.9118\n",
            "7/7 [==============================] - 207s 29s/step - loss: 6.9104\n",
            "7/7 [==============================] - 210s 30s/step - loss: 6.9097\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.8970\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.8927\n",
            "7/7 [==============================] - 210s 30s/step - loss: 6.8920\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.8870\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.8745\n",
            "7/7 [==============================] - 214s 31s/step - loss: 6.8742\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.8646\n",
            "7/7 [==============================] - 205s 29s/step - loss: 6.8566\n",
            "7/7 [==============================] - 214s 31s/step - loss: 6.8554\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.8381\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.8405\n",
            "7/7 [==============================] - 210s 30s/step - loss: 6.8300\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.8304\n",
            "7/7 [==============================] - 208s 30s/step - loss: 6.8140\n",
            "7/7 [==============================] - 212s 30s/step - loss: 6.8115\n",
            "7/7 [==============================] - 207s 30s/step - loss: 6.8074\n",
            "7/7 [==============================] - 210s 30s/step - loss: 6.8011\n",
            "7/7 [==============================] - 205s 29s/step - loss: 6.7878\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.7705\n",
            "7/7 [==============================] - 210s 30s/step - loss: 6.7738\n",
            "7/7 [==============================] - 207s 30s/step - loss: 6.7596\n",
            "7/7 [==============================] - 205s 29s/step - loss: 6.7461\n",
            "7/7 [==============================] - 211s 30s/step - loss: 6.7369\n",
            "7/7 [==============================] - 205s 29s/step - loss: 6.7276\n",
            "7/7 [==============================] - 206s 29s/step - loss: 6.7146\n",
            "7/7 [==============================] - 208s 30s/step - loss: 6.6974\n",
            "7/7 [==============================] - 204s 29s/step - loss: 6.6940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPJ76R2jgxyG"
      },
      "source": [
        "Model loss decreasing very slow, 50 epochs were trained > 3 hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRQs2-1Eeqz9"
      },
      "source": [
        "Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VDOUUt2EHZ_p",
        "outputId": "c5c1b8ca-0541-4c43-afdc-e0c2ee4ad2c9"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_1'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWaWiEt7H2eI"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Number of characters to generate\n",
        "    num_generate = 30\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low temperature results in more predictable text.\n",
        "    # Higher temperature results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    temperature = 0.5\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ' '.join(text_generated))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NASUKZrhH2hC",
        "outputId": "df665729-4c1a-417c-9af0-b753a60bf5e1"
      },
      "source": [
        "print(generate_text(model, start_string=\"k\"))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kon to a in was to to to in aint my for zzzbut i the in and you never the the you the from up to you a a skinning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXOD2YsRH2mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b9427d-f61e-4633-f2ce-667effe45753"
      },
      "source": [
        "print(generate_text(model, start_string=\"n\"))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nzzzwait right the the the of ok this dimension mothafuckers zzzdont plastic a spider to get to the is like in me go a of ready of in you of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX3aUlkysE8s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}