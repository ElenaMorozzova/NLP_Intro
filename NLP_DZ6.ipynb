{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP DZ6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKJHevXpdir3pTTgnkfhc+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d11d36a34b094155896a8e805bff18b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_99b5833726d248539561391240c8cc04",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_959cc79e3bc643bf898b4d273ddf6db1",
              "IPY_MODEL_74f32a8cc418479f88572ffe87ef1d91",
              "IPY_MODEL_1844af8192e34bff9deea758a40dac53"
            ]
          }
        },
        "99b5833726d248539561391240c8cc04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "959cc79e3bc643bf898b4d273ddf6db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd7add38266143a38d6f3b93a6565bc3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76b7957034784179b4c1482ed4ad1221"
          }
        },
        "74f32a8cc418479f88572ffe87ef1d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1583c8a5d9744f93a53699f71e76fa94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e15a4310d178491691b11213348eaec2"
          }
        },
        "1844af8192e34bff9deea758a40dac53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5675d14aa78a4fa494ec3b4920e460f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25000/? [00:45&lt;00:00, 529.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92bb2c84ea0c4a46966108ec515365bb"
          }
        },
        "bd7add38266143a38d6f3b93a6565bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76b7957034784179b4c1482ed4ad1221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1583c8a5d9744f93a53699f71e76fa94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e15a4310d178491691b11213348eaec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5675d14aa78a4fa494ec3b4920e460f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92bb2c84ea0c4a46966108ec515365bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e5759c479e94b8eb53c8b9f34535ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_47b4c74d55264ed1910f563677ada9a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10f6cd2fa41644f7bee8a34978af4327",
              "IPY_MODEL_1d7f5709c91b498883da11badb73c857",
              "IPY_MODEL_a164a426efa14ddc8138d2f941272751"
            ]
          }
        },
        "47b4c74d55264ed1910f563677ada9a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10f6cd2fa41644f7bee8a34978af4327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a6adb26bb4954f418528a206166ef3d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18fbf0be5cee4ec2a8b60d9dee97aef9"
          }
        },
        "1d7f5709c91b498883da11badb73c857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6b986d8c46f4a2499fa5f9cb7e39922",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0130277cc7524c2682f7928280395ec5"
          }
        },
        "a164a426efa14ddc8138d2f941272751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7b0ff3ca28646b3894c076dfde9c1d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25000/? [00:44&lt;00:00, 592.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c09520a3d184036a66554de7160874f"
          }
        },
        "a6adb26bb4954f418528a206166ef3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18fbf0be5cee4ec2a8b60d9dee97aef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6b986d8c46f4a2499fa5f9cb7e39922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0130277cc7524c2682f7928280395ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7b0ff3ca28646b3894c076dfde9c1d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c09520a3d184036a66554de7160874f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElenaMorozzova/NLP_Intro/blob/main/NLP_DZ6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXprAxDXtylD",
        "outputId": "4f4ec3a0-2cba-44e5-ddc6-9e16d210d473"
      },
      "source": [
        "!wget -O imdb.zip -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1vrQ5czMHoO3pEnmofFskymXMkq_u1dPc\"\n",
        "!unzip imdb.zip\n",
        "!pip -q install eli5\n",
        "!pip -q install spacy\n",
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  imdb.zip\n",
            "replace test.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: т\n",
            "error:  invalid response [т]\n",
            "replace test.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace train.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tawhSrRbtzWs"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1d1-5FwxK53ePwygNWeG7jhsOWZbi5HOv'})\n",
        "downloaded.GetContentFile('train_docs.pkl')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1MMOY477t965G0C5DtXeREVp0X85UaNq5'})\n",
        "downloaded.GetContentFile('test_docs.pkl')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTSpmhZwuDRA",
        "outputId": "da8841f2-3970-4cf8-bda5-3c38193f1cf8"
      },
      "source": [
        "#Датасет взят с http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "!head train.tsv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is_positive\treview\r\n",
            "0\t\"Dreamgirls, despite its fistful of Tony wins in an incredibly weak year on Broadway, has never been what one would call a jewel in the crown of stage musicals. However, that is not to say that in the right cinematic hands it could not be fleshed out and polished into something worthwhile on-screen. Unfortunately, what transfers to the screen is basically a slavishly faithful version of the stage hit with all of its inherent weaknesses intact. First, the score has never been one of the strong points of this production and the film does not change that factor. There are lots of songs (perhaps too many?), but few of them are especially memorable. The closest any come to catchy tunes are the title song and One Night Only - the much acclaimed And I Am Telling You That I Am Not Going is less a great song than it is a dramatic set piece for the character of Effie (Jennifer Hudson). The film is slick and technically well-produced, but the story and characters are surprisingly thin and lacking in any resonance. There is some interest in the opening moments, watching Jamie Foxx's Svengali-like manager manipulate his acts to the top, but that takes a back seat in the latter portion of the film, when the story conveniently tries to cast him as a villain, despite his having been right from a business stand-point for a good majority of the film. Beyonce Knowles is lovely and sings her songs perfectly well, but is stuck with a character who is basically all surface glitz. Anika Noni Rose as the third member of the Dreamgirls trio literally has nothing to do for the entire film. Eddie Murphy acquits himself well as a singer obviously based on James Brown, but the role is not especially meaty and ultimately has little impact. Foxx would seem ideal casting, but he seems oddly withdrawn and bored. The film's biggest selling point is surely former American Idol contestant/Oscar winner Jennifer Hudson in the central role of Effie White, the temperamental singer who gets booted from the group and makes a triumphant closing act return. For me, Effie has always been a big problem in both the show and the movie. The film obviously wants you to feel sorry for her and rather ham-handedly takes her side, but I have never been sure that this character deserves that kind of devotion. From the start, Effie conducts herself for the most part like an obnoxious, egotistical, self-centered diva, who is more interested in what everyone else can do for her rather than having much vested interest in the group of which she is a part. When she is booted from the group for her unprofessionalism and bad attitude, the charges are more than well-founded, but the stage show/film seem to think Effie should be cut unlimited slack simply because she has a great voice. Even though the film tries to soften some of Effie's harder edges to make her more likable, the charges still stand. Her story becomes more manipulative by suggesting she should have our further sympathy because she is an unwed mother struggling to raise her daughter - using the implication that (much like the talent card) motherhood immediately makes any behavior excusable. Indeed the only big effort the film makes to show Effie's mothering is to tell us about it and then include a scene where she barks at her daughter in the unemployment office, insists that the girl has \"\"no father\"\" and then refuse to look for gainful employment to support them since singing is all she knows. In the hands of a skillful actress, the gaps could perhaps have been remedied with technique and charisma. Unfortunately, Hudson is not that actress. She sings well, but the dialog-driven moments do not come naturally to her nor do high emotional moments. Effie's signature moment (the aforementioned And I Am Telling You... number) is well-sung by Hudson, but emotionally flat in the acting department. Effie is supposed to expressing her rage and desperation at her predicament, but Hudson comes off as a cabaret performer belting out a hot number. All in all, not quite the emotional highlight one expects. The latter portion of the film is basically a predictable melange of events that maneuver Foxx into Hudson's earlier position and allow her to strut back in and lord it over everyone. Foxx's criminal offenses in the film are undoubtedly par for the course of many struggling record producers, but the film's seeming implication that he has it coming because he helped usher in the disco era is rather ridiculous, not to mention pretentious and condescending, particularly coming from a film with all of the depth of a puddle. The end result is a faithful rendition of the stage hit, drained of emotion, energy or anything that can be described as dynamic.\"\r\n",
            "0\tThis show comes up with interesting locations as fast as the travel channel. It is billed as reality but in actuality it is pure prime time soap opera. It's tries to use exotic locales as a facade to bring people into a phony contest & then proceeds to hook viewers on the contestants soap opera style.<br /><br />It also borrows from an early CBS game show pioneer- Beat The Clock- by inventing situations for its contestants to try & overcome. Then it rewards the winner money. If they can spice it up with a little interaction between the characters, even better. While the game format is in slow motion versus Beat The Clock- the real accomplishment of this series is to escape reality. <br /><br />This show has elements of several types of successful past programs. Reality television, hardly, but if your hooked on the contestants, locale or contest, this is your cup of tea. If your not, this entire series is as I say, drivel dripping with gravy. It is another show hiding behind the reality label which is the trend it started in 2000.<br /><br />It is slick & well produced, so it might last a while yet. After all, so do re-runs of Gilligan's Island, Green Acres, The Beverly Hillbillies & The Brady Bunch. This just doesn't employ professional actors. The intelligence level is about the same.\r\n",
            "1\tI simply love this movie. I also love the Ramones, so I am sorta biased to begin with in the first place. There isn't a lot of critical praise to give this film, either you like it or you don't. I think it's a great cult movie.\r\n",
            "0\t\"Spoilers ahead if you want to call them that...<br /><br />I would almost recommend this film just so people can truly see a 1/10. Where to begin, we'll start from the top...<br /><br />THE STORY: Don't believe the premise - the movie has nothing to do with abandoned cars, and people finially understanding what the mysterious happenings are. It's a draub, basic, go to cabin movie with no intensity or \"\"effort\"\".<br /><br />THE SCREENPLAY: I usually give credit to indie screenwriters, it's hard work when you are starting out...but this is crap. The story is flat - it leaves you emotionless the entire movie. The dialogue is extremely weak and predictable boasting lines of \"\"Woah, you totally freaked me out\"\" and \"\"I was wondering if you'd uh...if you'd like to..uh, would you come to the cabin with me?\"\". It makes me want to rip out all my hair, one strand at a time and feed it to myself.<br /><br />THE CHARACTERS: HOLY CRAP!!!! Some have described the characters as flat, I want to take it one step further and say that they actually have a reverse character arch.. They actually start working on a parallel universe and almost start acting backwards...<br /><br />THE ACTORS: Worse than the characters are the actors. They take already poor written characters and add in terrible high school drama acting. The \"\"Woah you totally freaked me out\"\" was said so monotone and slow - like it was dumbed down. I could complain for hours on the actors alone.<br /><br />TECHNICAL: LIGHTING: An eight year old would be disappointed with lighting on this movie. Too shadowy in areas, too bleached in others. The director shouldn't use light as an emotion until he learns how to light a basic scene properly. Baby Steps! SOUND: How many sound guys does it take to make a really shotty sounding movie? 9. With that many sound guys this should sound amazing but quite the opposite has occured. There is one scene in particular that really sticks out, these guys are driving in a car and the sound of the car changes with every camera angle....WEAK! CAMERA: Learn to use it.<br /><br />Anyway, I'm running out of complaining space.....rent it - I dare you...Rent it and learn from it...give it a 1 rating..it deserves it.<br /><br />Signing off... Amanda Christmas\"\r\n",
            "1\t\"My all-time favorite movie! I have seen many movies, but this one beats them all! Excelent acting, wonderful story. You will, as a \"\"normal\"\" caring person start to love George. Altough he is an actor, he is also himself and a very lovable person. And maby most important thing: you will learn to respect & look different to people with Down Syndrome.\"\r\n",
            "1\tWonderful film, one of the best horror films of the 70s. She is realistic settings and atmospheres. As usual it was inevitable the usual negative comments. I have noticed that most horror films of a certain period many times fail to reach even sufficiency. Obviously because most horror movies are old and must be denigrati, is like a mental mechanism that moves the minds of the potential of music critics here.<br /><br />Before you read the review already knew what was the final judgment. In the film a good gift because 10 is really well done. Raines reads quite well and the film as a way in which it was produced reminds me a lot of Kubrick films. He really impression. Excellent film really. I consider a film anthology of years'70.\r\n",
            "0\tand shot in Vancouver with the 'mountains' of the low country of South Carolina visible in the background. For heaven's sake, they should have reset the location. There are no coastal mountains in South Carolina. Period.<br /><br />Lame visuals. They should have been beautiful. And the story limped along.<br /><br />I really don't understand why it was such a hit as a book, although I have to admit it's one I haven't read as yet. Usually I read the book and give the film a miss. There was nothing in this movie that made me want to buy the book, or even borrow it from the library.<br /><br />Verdict: The Mermaid Chair seemed pretty shallow to moi.\r\n",
            "1\tThis is the best dub I've ever heard by Disney, as well as the best adaptation since the biggest abuse ever on soundtrack, themes, characters, dialogues in Kiki Delivery Service. Urrrghhh<br /><br />This one has different atmosphere, especially the deviation from the common heroine. This one has both hero and heroine (although I don't really endorse the use of hero & heroine here, since Miyazaki is out from the stereotype & common theme). As usual, after being introduced by Spirited away, amazed by Mononoke, troubled by Grave of Fireflies, and deeply touched by Majo no Takkyuubin , this one start with a bit doubt in my part. Wondering if this will be the first Ghibi's dud. Well, in the end just like Only Yesterday and Whisper of the Heart, I ended up giving 10 rating. I'd give 9.8 rating, but the additional 0.2 is there to share the good feeling by encouraging people to see the movie.<br /><br />SPOILER Somehow I see this as a sad movie, people die in this one, the lonely robot, the abandoned place, and it ends with destruction. It is as if mankind really can't live with too much power. The collapsing scene gave me patches of Metropolis ending. It's just sad somehow. The plot is apparent in most reviews and the soundtrack rules as well (as always). Joe Hisaishi really belongs to Uematsu, Kanno, Williams caliber.People who can brings a movie, a game, an event to life, even to be a lingering moments by astounding composition.<br /><br />This is a feel good movie that used to be part of US cinema in the classic days (It's a Wonderful Life etc etc). Well, things change....\r\n",
            "1\t\"Linking story: another first-time viewing for me and, again, this is one of the most popular of the Amicus anthologies - and it's easy to see why, though I realize how the film's rather meaningless title could be misleading for some; I certainly fancied director Peter Duffell's choice - DEATH AND THE MAIDEN (which, incidentally, is a classical piece by Schubert that is heard in the film during the Peter Cushing episode) - a great deal more. Though the linking device itself is not all that great, the episodes are all equally compelling and enjoyable. Production values come off as very respectable indeed for the budget Duffell had to work with. The latter infuses the film with a great deal of style which is not so common with this type of film and, frankly, it makes one regret the fact that he wished to distance himself from the genre (though more so as not to be typecast rather than because he felt it was beneath him).<br /><br />Now to the individual stories themselves: <br /><br />\"\"Method For Murder\"\": the opening segment does not offer any real surprises but, to make up for this, it's quietly suspenseful and appropriately creepy at times (Tom Adams' 'fictitious' villain looking like the long-lost brother of Boris Karloff from THE OLD DARK HOUSE [1932]); also, it ends with a satisfactory DIABOLIQUE-type twist, and features a fairly intense role for Denholm Elliott in the lead. That's all we need out of it, really.<br /><br />\"\"Waxworks\"\": for the second story we are introduced to a curiously romantic mood which is quite unusual for this type of film; Peter Cushing and Joss Ackland are both excellent (as well as impeccably dressed) in their roles of two jilted lovers of a woman who continues to obsess them even after such a long time, and whose friendly rivalry can only lead them blindly and inexorably to a fate that is literally worse than death; an ominous hallucination scene with Peter Cushing is quite well done in view of the limited resources at hand, and Ackland's inexplicable inability - or unwillingness - to leave town somewhat recalls the house-trapped aristocrats of Bunuel's THE EXTERMINATING ANGEL (1962).<br /><br />\"\"Sweets To The Sweet\"\": this is perhaps the finest episode of all - with his ambiguous role here, Christopher Lee continues to demonstrate his versatility and he is matched by an understanding Nyree Dawn Porter and the deceptive innocence of Chloe Franks (who appears as Lee's daughter). The film's treatment of the occult here is both subtle and mature, culminating in a powerful and extremely chilling 'curtain'. Trivia Note: Chloe Franks appears as a grown-up in the featurette included on the disc, and when I saw her I felt an immediate familiarity with her face but couldn't quite put my finger on it. Later, on reading her filmography, it was revealed to me that she had played one of the leads in the long-running stage adaptation of Agatha Christie's \"\"The Mousetrap\"\" in London's West End, which my brother and I were fortunate enough to catch while we there on holiday in the Summer of 2002! Needless to say, we had no idea then that she had once created such a delicate - and delicious - portrayal in sheer evil, mainly by virtue of her peculiar look and a devilish smile!! <br /><br />\"\"The Cloak\"\": a wacky but oddly reverent vampire tale (that still manages to debunk many of the myths attached to the subgenre, while inventing some new ones!) which takes in some wonderful digs at exploitation cinema and, at one point, Christopher Lee himself!; Jon Pertwee is marvelous as the campy horror star who gets more than he bargained for when he attempts to bring a measure of authenticity to his work; Ingrid Pitt sends up her image nicely though her role is somewhat subsidiary to the proceedings; Geoffrey Bayldon (made up to look like Ernest Thesiger) also has a memorably quirky bit; the 'silent-cinema' style of the ending was a pretty audacious one to pull on an audience, I suppose - and, while some of the humor comes off as heavy-handed a' la THE FEARLESS VAMPIRE KILLERS (1967) or THEATRE OF BLOOD (1973), it's also rather infectious and certainly ends the film on a high (and highly unusual) note! <br /><br />Video and audio quality are relatively satisfactory, considering I had no other version to compare it with; the main culprit is some noticeable print damage but this is never so nasty as to affect one's enjoyment of the film. As for the extras, beginning with the Audio Commentary: frankly, this is one of the finest chats about a genre film that I can remember listening to; Jonathan Rigby gets to butt in with his opinion more than is usual for a moderator but his effort certainly allows director Peter Duffell to touch on every aspect of the production (whereas with some other films, you're left rather expecting there to be more!) and, as such, it's an extremely pleasant track that complements the main feature very nicely indeed. The featurette \"\"A-Rated Horror Film\"\" is a worthwhile effort with Peter Duffell again at center-stage but this time backed up with valid, if all-too-brief, contributions from producer Max J. Rosenberg and stars Chloe Franks, Ingrid Pitt and Geoffrey Bayldon. We also get film notes, reviews, bios and a poster/stills gallery which, again, are wonderfully assembled (with the contemporary reviews being something of a novelty - and a welcome one at that).\"\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptRQsL0Nv4aP"
      },
      "source": [
        "**Анализ тональности текста**\n",
        "\n",
        "Классификация отзывов с IMDB на положительные/отрицательные."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-8VhnsbuDzG",
        "outputId": "87730e81-cf6c-43f9-dcd8-ef97645022e5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.tsv\", delimiter=\"\\t\")\n",
        "test_df = pd.read_csv(\"test.tsv\", delimiter=\"\\t\")\n",
        "\n",
        "print('Train size = {}'.format(len(train_df)))\n",
        "print('Test size = {}'.format(len(test_df)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size = 25000\n",
            "Test size = 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgHc7CW6ul16",
        "outputId": "a4b94838-51d5-46f4-80e3-c9002ea3f874"
      },
      "source": [
        "import re\n",
        "#Избавимся от переносов <br />\n",
        "pattern = re.compile('<br />')\n",
        "\n",
        "print(train_df['review'].iloc[3])\n",
        "print(pattern.subn(' ', train_df['review'].iloc[3])[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spoilers ahead if you want to call them that...<br /><br />I would almost recommend this film just so people can truly see a 1/10. Where to begin, we'll start from the top...<br /><br />THE STORY: Don't believe the premise - the movie has nothing to do with abandoned cars, and people finially understanding what the mysterious happenings are. It's a draub, basic, go to cabin movie with no intensity or \"effort\".<br /><br />THE SCREENPLAY: I usually give credit to indie screenwriters, it's hard work when you are starting out...but this is crap. The story is flat - it leaves you emotionless the entire movie. The dialogue is extremely weak and predictable boasting lines of \"Woah, you totally freaked me out\" and \"I was wondering if you'd uh...if you'd like to..uh, would you come to the cabin with me?\". It makes me want to rip out all my hair, one strand at a time and feed it to myself.<br /><br />THE CHARACTERS: HOLY CRAP!!!! Some have described the characters as flat, I want to take it one step further and say that they actually have a reverse character arch.. They actually start working on a parallel universe and almost start acting backwards...<br /><br />THE ACTORS: Worse than the characters are the actors. They take already poor written characters and add in terrible high school drama acting. The \"Woah you totally freaked me out\" was said so monotone and slow - like it was dumbed down. I could complain for hours on the actors alone.<br /><br />TECHNICAL: LIGHTING: An eight year old would be disappointed with lighting on this movie. Too shadowy in areas, too bleached in others. The director shouldn't use light as an emotion until he learns how to light a basic scene properly. Baby Steps! SOUND: How many sound guys does it take to make a really shotty sounding movie? 9. With that many sound guys this should sound amazing but quite the opposite has occured. There is one scene in particular that really sticks out, these guys are driving in a car and the sound of the car changes with every camera angle....WEAK! CAMERA: Learn to use it.<br /><br />Anyway, I'm running out of complaining space.....rent it - I dare you...Rent it and learn from it...give it a 1 rating..it deserves it.<br /><br />Signing off... Amanda Christmas\n",
            "Spoilers ahead if you want to call them that...  I would almost recommend this film just so people can truly see a 1/10. Where to begin, we'll start from the top...  THE STORY: Don't believe the premise - the movie has nothing to do with abandoned cars, and people finially understanding what the mysterious happenings are. It's a draub, basic, go to cabin movie with no intensity or \"effort\".  THE SCREENPLAY: I usually give credit to indie screenwriters, it's hard work when you are starting out...but this is crap. The story is flat - it leaves you emotionless the entire movie. The dialogue is extremely weak and predictable boasting lines of \"Woah, you totally freaked me out\" and \"I was wondering if you'd uh...if you'd like to..uh, would you come to the cabin with me?\". It makes me want to rip out all my hair, one strand at a time and feed it to myself.  THE CHARACTERS: HOLY CRAP!!!! Some have described the characters as flat, I want to take it one step further and say that they actually have a reverse character arch.. They actually start working on a parallel universe and almost start acting backwards...  THE ACTORS: Worse than the characters are the actors. They take already poor written characters and add in terrible high school drama acting. The \"Woah you totally freaked me out\" was said so monotone and slow - like it was dumbed down. I could complain for hours on the actors alone.  TECHNICAL: LIGHTING: An eight year old would be disappointed with lighting on this movie. Too shadowy in areas, too bleached in others. The director shouldn't use light as an emotion until he learns how to light a basic scene properly. Baby Steps! SOUND: How many sound guys does it take to make a really shotty sounding movie? 9. With that many sound guys this should sound amazing but quite the opposite has occured. There is one scene in particular that really sticks out, these guys are driving in a car and the sound of the car changes with every camera angle....WEAK! CAMERA: Learn to use it.  Anyway, I'm running out of complaining space.....rent it - I dare you...Rent it and learn from it...give it a 1 rating..it deserves it.  Signing off... Amanda Christmas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZW1ttjaul4W"
      },
      "source": [
        "train_df['review'] = train_df['review'].apply(lambda text: pattern.subn(' ', text)[0])\n",
        "test_df['review'] = test_df['review'].apply(lambda text: pattern.subn(' ', text)[0])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISJ_i2z9ul67"
      },
      "source": [
        "#Используем countvectorizer для составления мешка слов и логистичекую регрессию для классификации\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSXtnGUzumDY",
        "outputId": "0895bdb7-5bea-4e87-80af-ec8a48843df8"
      },
      "source": [
        "model.fit(train_df['review'], train_df['is_positive'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX2vEqw1uD5M",
        "outputId": "9cde7fe3-a7f6-4e8d-f0cb-3618149404d8"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "#Считаем accuracy модели\n",
        "def eval_model(model, test_df):\n",
        "    preds = model.predict(test_df['review'])\n",
        "    print('Test accuracy = {:.2%}'.format(accuracy_score(test_df['is_positive'], preds)))\n",
        "    \n",
        "eval_model(model, test_df)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 86.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "id": "2x6zuknBu6YU",
        "outputId": "238e4546-ad11-4968-8281-a276a9d8b0a3"
      },
      "source": [
        "#Посмотрим топ слов, которые влияют на классификатор (веса)\n",
        "import eli5\n",
        "eli5.show_weights(classifier, vec=vectorizer, top=40)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
              "                    Weight<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 84.41%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.855\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        refreshing\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 84.97%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.760\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        wonderfully\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 85.40%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.689\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        funniest\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 85.65%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.647\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        surprisingly\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 85.79%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.626\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        rare\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.99%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.432\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        superb\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.19%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.401\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        excellent\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.42%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.365\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        incredible\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.51%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.351\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        perfect\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.83%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.302\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        delightful\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.08%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.264\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        vengeance\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.08%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 37681 more positive &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.97%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 37129 more negative &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.97%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.280\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        dull\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.97%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.281\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        worse\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.88%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.295\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        mildly\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.83%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.303\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        redeeming\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.53%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.349\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        baldwin\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.49%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.355\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        wooden\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.47%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.357\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        weak\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.33%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.379\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        badly\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.24%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.393\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        horrible\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.17%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.405\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        mst3k\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.09%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.416\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        save\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.05%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.423\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        lame\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.87%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.452\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        mediocre\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.31%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.541\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        pointless\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.13%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.569\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        alright\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.12%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.570\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        unfunny\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.02%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.588\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        forgettable\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.91%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.605\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        disappointing\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.62%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.653\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        boring\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.42%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.686\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        avoid\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.19%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.723\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        fails\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.18%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.725\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        awful\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.17%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.727\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        laughable\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 83.67%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.983\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        mess\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 82.75%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.143\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        lacks\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 81.77%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.320\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        worst\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 81.60%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.350\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        poorly\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.17%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.615\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        waste\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.648\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        disappointment\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "go5AAEJvu6bP",
        "outputId": "183900f1-3b9f-4af4-a768-1db11dcac714"
      },
      "source": [
        "#Посмотрим на примеры неправильной классификации\n",
        "import numpy as np\n",
        "\n",
        "preds = model.predict(test_df['review'])\n",
        "incorrect_pred_index = np.random.choice(np.where(preds != test_df['is_positive'])[0])\n",
        "\n",
        "eli5.show_prediction(classifier, test_df['review'].iloc[incorrect_pred_index],\n",
        "                     vec=vectorizer, targets=['positive'], target_names=['negative', 'positive'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=positive\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.068</b>, score <b>-2.619</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 99.42%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.016\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.603\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 85.79%); opacity: 0.85\" title=\"-0.197\">absolutely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.77%); opacity: 0.81\" title=\"0.035\">corrosive</span><span style=\"opacity: 0.80\">! </span><span style=\"background-color: hsl(0, 100.00%, 78.07%); opacity: 0.88\" title=\"-0.366\">director</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.95%); opacity: 0.85\" title=\"0.234\">arthur</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.52%); opacity: 0.81\" title=\"-0.038\">hiller</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.01%); opacity: 0.82\" title=\"0.102\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.03%); opacity: 0.85\" title=\"-0.233\">writer</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.57%); opacity: 0.81\" title=\"-0.037\">paddy</span><span style=\"opacity: 0.80\"> chayefsky </span><span style=\"background-color: hsl(0, 100.00%, 94.67%); opacity: 0.81\" title=\"-0.049\">dismantle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.28%); opacity: 0.88\" title=\"0.337\">american</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.22%); opacity: 0.90\" title=\"-0.436\">hospital</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.10%); opacity: 0.81\" title=\"0.031\">system</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.07%); opacity: 0.80\" title=\"0.011\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.21%); opacity: 0.81\" title=\"-0.055\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.14%); opacity: 0.90\" title=\"-0.438\">wicked</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.99%); opacity: 0.80\" title=\"0.004\">comedy</span><span style=\"opacity: 0.80\">/</span><span style=\"background-color: hsl(0, 100.00%, 94.88%); opacity: 0.81\" title=\"-0.046\">drama</span><span style=\"opacity: 0.80\">/</span><span style=\"background-color: hsl(120, 100.00%, 89.82%); opacity: 0.83\" title=\"0.122\">whodunit</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.22%); opacity: 0.90\" title=\"-0.436\">hospital</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 66.88%); opacity: 0.95\" title=\"-0.660\">depicted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.60%); opacity: 0.86\" title=\"-0.263\">here</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.03%); opacity: 0.82\" title=\"0.071\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.90%); opacity: 0.81\" title=\"-0.046\">fraught</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.07%); opacity: 0.80\" title=\"0.011\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.16%); opacity: 0.81\" title=\"0.030\">problems</span><span style=\"opacity: 0.80\">...</span><span style=\"background-color: hsl(0, 100.00%, 97.89%); opacity: 0.80\" title=\"-0.013\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.93%); opacity: 0.82\" title=\"0.088\">protesting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.68%); opacity: 0.90\" title=\"0.424\">neighbors</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.71%); opacity: 0.80\" title=\"0.014\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.28%); opacity: 0.80\" title=\"-0.019\">irate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.90%); opacity: 0.84\" title=\"0.156\">patients</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.71%); opacity: 0.80\" title=\"0.014\">to</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 61.93%); opacity: 0.99\" title=\"-0.805\">potential</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.49%); opacity: 0.84\" title=\"-0.183\">serial</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.93%); opacity: 0.81\" title=\"-0.022\">killer</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.57%); opacity: 0.81\" title=\"-0.026\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.11%); opacity: 0.82\" title=\"0.070\">loose</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 84.46%); opacity: 0.85\" title=\"-0.224\">george</span><span style=\"opacity: 0.80\"> c. </span><span style=\"background-color: hsl(0, 100.00%, 74.14%); opacity: 0.91\" title=\"-0.463\">scott</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.03%); opacity: 0.82\" title=\"0.071\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.79%); opacity: 0.86\" title=\"0.281\">top</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.74%); opacity: 0.83\" title=\"-0.141\">doctor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.58%); opacity: 0.85\" title=\"0.201\">who</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 96.57%); opacity: 0.81\" title=\"-0.026\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.05%); opacity: 0.80\" title=\"-0.012\">brink</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.92%); opacity: 0.82\" title=\"-0.073\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.09%); opacity: 0.82\" title=\"0.085\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.75%); opacity: 0.86\" title=\"0.260\">own</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.86%); opacity: 0.81\" title=\"0.034\">nervous</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.17%); opacity: 0.83\" title=\"0.134\">breakdown</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 92.35%); opacity: 0.82\" title=\"0.081\">gets</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.61%); opacity: 0.84\" title=\"0.181\">involved</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.07%); opacity: 0.80\" title=\"0.011\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.51%); opacity: 0.87\" title=\"-0.309\">free</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 97.28%); opacity: 0.80\" title=\"-0.019\">spirited</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.78%); opacity: 0.87\" title=\"0.281\">diana</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.64%); opacity: 0.82\" title=\"0.077\">rigg</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.01%); opacity: 0.82\" title=\"0.102\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.29%); opacity: 0.80\" title=\"0.010\">her</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.00%); opacity: 0.85\" title=\"-0.213\">wacky</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.96%); opacity: 0.85\" title=\"0.234\">father</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.62%); opacity: 0.80\" title=\"0.007\">barnard</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.89%); opacity: 0.80\" title=\"0.013\">hughes</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 87.60%); opacity: 0.84\" title=\"-0.162\">alternately</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 69.51%); opacity: 0.94\" title=\"-0.586\">depressing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.01%); opacity: 0.82\" title=\"0.102\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.32%); opacity: 0.86\" title=\"0.248\">uproarious</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.22%); opacity: 0.90\" title=\"-0.436\">hospital</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.66%); opacity: 0.81\" title=\"-0.036\">features</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.19%); opacity: 0.82\" title=\"0.099\">some</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.92%); opacity: 0.82\" title=\"-0.073\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.75%); opacity: 0.89\" title=\"0.374\">most</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.28%); opacity: 0.83\" title=\"0.114\">acid</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 95.24%); opacity: 0.81\" title=\"-0.041\">tinged</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.30%); opacity: 0.82\" title=\"0.067\">dialog</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.75%); opacity: 0.89\" title=\"-0.398\">imaginable</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(0, 100.00%, 76.98%); opacity: 0.89\" title=\"-0.392\">note</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.84%); opacity: 0.82\" title=\"-0.074\">how</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.14%); opacity: 0.91\" title=\"-0.463\">scott</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.48%); opacity: 0.83\" title=\"-0.146\">describes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.09%); opacity: 0.82\" title=\"0.085\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.87%); opacity: 0.91\" title=\"0.470\">love</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.04%); opacity: 0.87\" title=\"-0.297\">making</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.01%); opacity: 0.82\" title=\"0.102\">session</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.07%); opacity: 0.80\" title=\"0.011\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.64%); opacity: 0.82\" title=\"0.077\">rigg</span><span style=\"opacity: 0.80\">). </span><span style=\"background-color: hsl(120, 100.00%, 87.21%); opacity: 0.84\" title=\"0.169\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.10%); opacity: 0.86\" title=\"0.252\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.61%); opacity: 0.81\" title=\"0.025\">has</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 77.80%); opacity: 0.89\" title=\"0.372\">lot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.92%); opacity: 0.82\" title=\"-0.073\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 61.47%); opacity: 0.99\" title=\"0.819\">great</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.64%); opacity: 0.84\" title=\"-0.180\">vignettes</span><span style=\"opacity: 0.80\">: </span><span style=\"background-color: hsl(0, 100.00%, 74.14%); opacity: 0.91\" title=\"-0.463\">scott</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.03%); opacity: 0.80\" title=\"0.004\">berating</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.52%); opacity: 0.80\" title=\"0.016\">head</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.05%); opacity: 0.90\" title=\"-0.440\">nurse</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.864\">nancy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.32%); opacity: 0.82\" title=\"0.082\">marchand</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.72%); opacity: 0.81\" title=\"-0.035\">after</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.34%); opacity: 0.82\" title=\"-0.097\">one</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.92%); opacity: 0.82\" title=\"-0.073\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.60%); opacity: 0.86\" title=\"-0.263\">here</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.49%); opacity: 0.82\" title=\"-0.079\">underlings</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.74%); opacity: 0.81\" title=\"0.061\">accidentally</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.54%); opacity: 0.86\" title=\"-0.243\">kills</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 88.74%); opacity: 0.83\" title=\"-0.141\">doctor</span><span style=\"opacity: 0.80\">; </span><span style=\"background-color: hsl(120, 100.00%, 93.01%); opacity: 0.82\" title=\"0.071\">daffy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.26%); opacity: 0.80\" title=\"-0.003\">administrator</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.07%); opacity: 0.84\" title=\"-0.172\">frances</span><span style=\"opacity: 0.80\"> sternhagen </span><span style=\"background-color: hsl(0, 100.00%, 82.43%); opacity: 0.86\" title=\"-0.267\">trying</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 62.85%); opacity: 0.98\" title=\"-0.777\">desperately</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.71%); opacity: 0.80\" title=\"0.014\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.42%); opacity: 0.83\" title=\"0.112\">collect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.53%); opacity: 0.80\" title=\"0.002\">insurance</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.82%); opacity: 0.84\" title=\"0.177\">info</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.89%); opacity: 0.80\" title=\"-0.013\">from</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 97.46%); opacity: 0.80\" title=\"-0.017\">waiting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.68%); opacity: 0.87\" title=\"0.283\">room</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.76%); opacity: 0.82\" title=\"0.107\">full</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.92%); opacity: 0.82\" title=\"-0.073\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.01%); opacity: 0.81\" title=\"0.057\">sick</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.68%); opacity: 0.82\" title=\"0.076\">people</span><span style=\"opacity: 0.80\">; </span><span style=\"background-color: hsl(0, 100.00%, 74.14%); opacity: 0.91\" title=\"-0.463\">scott</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.74%); opacity: 0.83\" title=\"-0.124\">getting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.63%); opacity: 0.83\" title=\"-0.109\">sobering</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 61.89%); opacity: 0.99\" title=\"-0.806\">advice</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.89%); opacity: 0.80\" title=\"-0.013\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.22%); opacity: 0.90\" title=\"-0.436\">hospital</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.48%); opacity: 0.86\" title=\"0.244\">psychiatrist</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.72%); opacity: 0.81\" title=\"-0.035\">after</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.75%); opacity: 0.93\" title=\"-0.552\">telling</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.42%); opacity: 0.83\" title=\"0.147\">him</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.92%); opacity: 0.82\" title=\"-0.073\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.09%); opacity: 0.82\" title=\"0.085\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.57%); opacity: 0.82\" title=\"-0.093\">woeful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.42%); opacity: 0.80\" title=\"0.017\">home</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 87.05%); opacity: 0.84\" title=\"0.172\">life</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 96.53%); opacity: 0.81\" title=\"-0.026\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.92%); opacity: 0.82\" title=\"-0.073\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.26%); opacity: 0.83\" title=\"-0.132\">acting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.03%); opacity: 0.82\" title=\"0.071\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.43%); opacity: 0.83\" title=\"0.112\">first</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 84.91%); opacity: 0.85\" title=\"0.214\">rate</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 74.14%); opacity: 0.91\" title=\"-0.463\">scott</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.01%); opacity: 0.82\" title=\"0.102\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.64%); opacity: 0.82\" title=\"0.077\">rigg</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.32%); opacity: 0.82\" title=\"-0.097\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.83%); opacity: 0.85\" title=\"0.196\">dynamite</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.01%); opacity: 0.82\" title=\"0.102\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.89%); opacity: 0.80\" title=\"0.013\">hughes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.03%); opacity: 0.82\" title=\"0.071\">is</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 82.76%); opacity: 0.86\" title=\"0.260\">real</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 68.36%); opacity: 0.94\" title=\"0.618\">surprise</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.035\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.03%); opacity: 0.82\" title=\"0.071\">is</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 61.61%); opacity: 0.99\" title=\"0.814\">masterpiece</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.07%); opacity: 0.80\" title=\"0.011\">with</span><span style=\"opacity: 0.80\"> chayefsky&#x27;s </span><span style=\"background-color: hsl(0, 100.00%, 66.71%); opacity: 0.95\" title=\"-0.664\">script</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.28%); opacity: 0.80\" title=\"-0.019\">earning</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 76.82%); opacity: 0.89\" title=\"0.396\">well</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 96.19%); opacity: 0.81\" title=\"-0.030\">deserved</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.59%); opacity: 0.87\" title=\"-0.307\">oscar</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(0, 100.00%, 96.91%); opacity: 0.81\" title=\"-0.022\">over</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.20%); opacity: 0.85\" title=\"-0.209\">such</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.57%); opacity: 0.94\" title=\"-0.612\">stiff</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.46%); opacity: 0.87\" title=\"0.310\">competition</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.56%); opacity: 0.81\" title=\"0.050\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.90%); opacity: 0.83\" title=\"-0.138\">klute</span><span style=\"opacity: 0.80\"> &amp; </span><span style=\"background-color: hsl(120, 100.00%, 71.81%); opacity: 0.92\" title=\"0.524\">sunday</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 73.84%); opacity: 0.91\" title=\"0.471\">bloody</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.81%); opacity: 0.92\" title=\"0.524\">sunday</span><span style=\"opacity: 0.80\">). </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.58%); opacity: 0.87\" title=\"-0.285\">opening</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.83%); opacity: 0.84\" title=\"0.158\">narration</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.03%); opacity: 0.82\" title=\"0.071\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.86%); opacity: 0.83\" title=\"0.122\">priceless</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHQGIrDO0Hx5"
      },
      "source": [
        "Задание 1\n",
        "\n",
        "Проверьте повысилось ли качество на стандартных подходах при лемматизации/и без неё"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJN4vls13Btr",
        "outputId": "b1af7211-3a79-40bf-dc2f-8b93637d491d"
      },
      "source": [
        "# import necessary libraries\n",
        "import nltk\n",
        "\n",
        "# word tokenization \n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "# Lemmatization\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6f8xjJRGuD-v",
        "outputId": "407a5d3e-cfb5-471d-9d61-4d952cb5bca5"
      },
      "source": [
        "# Defining a function to perform tokenization, Stemming/Lemmatization and to remove stop words\n",
        "\n",
        "def token_stem_stop(string):\n",
        "    stem_rew = \" \"\n",
        "    tokens = word_tokenize(string) # word tokenization\n",
        "#     print(tokens)\n",
        "    for word in tokens:\n",
        "        if word.lower() not in stop_words: # removing stop words\n",
        "            stem_word = ps.stem(word) # stemming\n",
        "            stem_rew = stem_rew + \" \" + stem_word\n",
        "    return str(stem_rew)\n",
        "\n",
        "# apply the function on the dataframe and create a new column to store\n",
        "train_df['review_processed'] = train_df['review'].apply(token_stem_stop) \n",
        "train_df.head() # showing the first five rows"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_positive</th>\n",
              "      <th>review</th>\n",
              "      <th>review_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Dreamgirls, despite its fistful of Tony wins i...</td>\n",
              "      <td>dreamgirl , despit fist toni win incred weak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>This show comes up with interesting locations ...</td>\n",
              "      <td>show come interest locat fast travel channel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I simply love this movie. I also love the Ramo...</td>\n",
              "      <td>simpli love movi . also love ramon , sorta b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Spoilers ahead if you want to call them that.....</td>\n",
              "      <td>spoiler ahead want call ... would almost rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>My all-time favorite movie! I have seen many m...</td>\n",
              "      <td>all-tim favorit movi ! seen mani movi , one ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_positive  ...                                   review_processed\n",
              "0            0  ...    dreamgirl , despit fist toni win incred weak...\n",
              "1            0  ...    show come interest locat fast travel channel...\n",
              "2            1  ...    simpli love movi . also love ramon , sorta b...\n",
              "3            0  ...    spoiler ahead want call ... would almost rec...\n",
              "4            1  ...    all-tim favorit movi ! seen mani movi , one ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo3AV2FJyYMt"
      },
      "source": [
        "test_df['review_processed'] = test_df['review'].apply(token_stem_stop)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMqH6l6z3-bQ",
        "outputId": "69c874bc-cf4a-4c98-be99-71cb7e86f866"
      },
      "source": [
        "# Обучим линейную регрессию на обработанных отзывах\n",
        "model.fit(train_df['review_processed'], train_df['is_positive'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alMd51pN3-dz",
        "outputId": "a01f5f9c-f1ef-477e-db50-97ad8020b109"
      },
      "source": [
        "#На обработанном лемматизированном столбце accuracy модели снизилась\n",
        "#Считаем accuracy модели\n",
        "def eval_model_pr(model, test_df):\n",
        "    preds = model.predict(test_df['review_processed'])\n",
        "    print('Test accuracy = {:.2%}'.format(accuracy_score(test_df['is_positive'], preds)))\n",
        "\n",
        "eval_model_pr(model, test_df)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 85.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjVhUp972LQt"
      },
      "source": [
        "Заменим CountVectorizer на TfidfVectorizer, чтобы учесть частотность слов и извлечем биграммы слов (параметр ngram_range)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu6lUWcM3-gk",
        "outputId": "166e716b-7c89-42fe-8af7-061e40934da0"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "# С TfidfVectorizer на необработанном столбце отзывов качество модели выше, чем с CountVectorizer \n",
        "model.fit(train_df['review'], train_df['is_positive'])\n",
        "eval_model(model, test_df)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 88.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRZr5WhsyYPZ",
        "outputId": "9eecda44-65b3-4208-b0a8-73b4fd7ce2f4"
      },
      "source": [
        "# На обработанном столбце отзывов качество модели также чуть хуже\n",
        "model.fit(train_df['review_processed'], train_df['is_positive'])\n",
        "eval_model_pr(model, test_df)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 87.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC5jAiuQ3VtD"
      },
      "source": [
        "**Задание 2** \n",
        "\n",
        "В текстах рецензий очень много именованных сущностей. Удалите из текстов какие-то из сущностей, чтобы не придавать им окраску. Запустите классификатор."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taVD4GEVyYR5"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load('en', disable=['parser'])\n",
        "\n",
        "train_docs = [doc for doc in nlp.pipe(train_df.review.values)]\n",
        "test_docs = [doc for doc in nlp.pipe(test_df.review.values)]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "M1tIE6vdZbEW",
        "outputId": "53112235-d041-454d-d2bf-ac500c4777eb"
      },
      "source": [
        "displacy.render(train_docs[0], style='ent', jupyter=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Dreamgirls\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", despite its fistful of \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tony\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " wins in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    an incredibly weak year\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " on \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Broadway\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
              "</mark>\n",
              ", has never been what one would call a jewel in the crown of stage musicals. However, that is not to say that in the right cinematic hands it could not be fleshed out and polished into something worthwhile on-screen. Unfortunately, what transfers to the screen is basically a slavishly faithful version of the stage hit with all of its inherent weaknesses intact. \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    First\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              ", the score has never been one of the strong points of this production and the film does not change that factor. There are lots of songs (perhaps too many?), but few of them are especially memorable. The closest any come to catchy tunes are the title song and \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    One Night\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
              "</mark>\n",
              " Only - the much acclaimed And I Am Telling You That I Am Not Going is less a great song than it is a dramatic set piece for the character of \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Effie\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " (\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jennifer Hudson\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "). The film is slick and technically well-produced, but the story and characters are surprisingly thin and lacking in any resonance. There is some interest in the opening moments, watching \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jamie Foxx's\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " Svengali-like manager manipulate his acts to the top, but that takes a back seat in the latter portion of the film, when the story conveniently tries to cast him as a villain, despite his having been right from a business stand-point for a good majority of the film. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Beyonce Knowles\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " is lovely and sings her songs perfectly well, but is stuck with a character who is basically all surface glitz. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Anika Noni Rose\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " as the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    third\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " member of the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Dreamgirls\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " trio literally has nothing to do for the entire film. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Eddie Murphy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " acquits himself well as a singer obviously based on \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    James Brown\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", but the role is not especially meaty and ultimately has little impact. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Foxx\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " would seem ideal casting, but he seems oddly withdrawn and bored. The film's biggest selling point is surely former \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    American Idol\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " contestant/\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Oscar\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " winner \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jennifer Hudson\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " in the central role of \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Effie White\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", the temperamental singer who gets booted from the group and makes a triumphant closing act return. For me, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Effie\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has always been a big problem in both the show and the movie. The film obviously wants you to feel sorry for her and rather ham-handedly takes her side, but I have never been sure that this character deserves that kind of devotion. From the start, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Effie\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " conducts herself for the most part like an obnoxious, egotistical, self-centered diva, who is more interested in what everyone else can do for her rather than having much vested interest in the group of which she is a part. When she is booted from the group for her unprofessionalism and bad attitude, the charges are more than well-founded, but the stage show/film seem to think \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Effie\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " should be cut unlimited slack simply because she has a great voice. Even though the film tries to soften some of \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Effie\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "'s harder edges to make her more likable, the charges still stand. Her story becomes more manipulative by suggesting she should have our further sympathy because she is an unwed mother struggling to raise her daughter - using the implication that (much like the talent card) motherhood immediately makes any behavior excusable. Indeed the only big effort the film makes to show \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Effie\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "'s mothering is to tell us about it and then include a scene where she barks at her daughter in the unemployment office, insists that the girl has &quot;no father&quot; and then refuse to look for gainful employment to support them since singing is all she knows. In the hands of a skillful actress, the gaps could perhaps have been remedied with technique and charisma. Unfortunately, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Hudson\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " is not that actress. She sings well, but the dialog-driven moments do not come naturally to her nor do high emotional moments. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Effie\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "'s signature moment (the aforementioned And I Am Telling You... number) is well-sung by \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Hudson\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", but emotionally flat in the acting department. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Effie\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " is supposed to expressing her rage and desperation at her predicament, but \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Hudson\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " comes off as a cabaret performer belting out a hot number. All in all, not quite the emotional highlight one expects. The latter portion of the film is basically a predictable melange of events that maneuver \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Foxx\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " into \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Hudson\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "'s earlier position and allow her to strut back in and lord it over everyone. \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Foxx\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "'s criminal offenses in the film are undoubtedly par for the course of many struggling record producers, but the film's seeming implication that he has it coming because he helped usher in the disco era is rather ridiculous, not to mention pretentious and condescending, particularly coming from a film with all of the depth of a puddle. The end result is a faithful rendition of the stage hit, drained of emotion, energy or anything that can be described as dynamic.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d11d36a34b094155896a8e805bff18b5",
            "99b5833726d248539561391240c8cc04",
            "959cc79e3bc643bf898b4d273ddf6db1",
            "74f32a8cc418479f88572ffe87ef1d91",
            "1844af8192e34bff9deea758a40dac53",
            "bd7add38266143a38d6f3b93a6565bc3",
            "76b7957034784179b4c1482ed4ad1221",
            "1583c8a5d9744f93a53699f71e76fa94",
            "e15a4310d178491691b11213348eaec2",
            "5675d14aa78a4fa494ec3b4920e460f5",
            "92bb2c84ea0c4a46966108ec515365bb"
          ]
        },
        "id": "V6ahN-hW0ViL",
        "outputId": "64891b32-d3d4-47bd-a493-2571c4780685"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "no_ent_train = []\n",
        "for i, doc in tqdm(enumerate((train_docs))):\n",
        "    plain_text=''\n",
        "    start_point=0\n",
        "    for ent in doc.ents:\n",
        "        plain_text = plain_text+train_df.iloc[i]['review'][start_point : ent.start_char]+' '+ent.label_+' '\n",
        "        start_point = ent.end_char   \n",
        "    no_ent_train.append(plain_text)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d11d36a34b094155896a8e805bff18b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lhebmgg0VlP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3e5759c479e94b8eb53c8b9f34535ad1",
            "47b4c74d55264ed1910f563677ada9a3",
            "10f6cd2fa41644f7bee8a34978af4327",
            "1d7f5709c91b498883da11badb73c857",
            "a164a426efa14ddc8138d2f941272751",
            "a6adb26bb4954f418528a206166ef3d3",
            "18fbf0be5cee4ec2a8b60d9dee97aef9",
            "e6b986d8c46f4a2499fa5f9cb7e39922",
            "0130277cc7524c2682f7928280395ec5",
            "b7b0ff3ca28646b3894c076dfde9c1d8",
            "8c09520a3d184036a66554de7160874f"
          ]
        },
        "outputId": "a812c45d-e60a-4d1d-be07-b5909cfb667b"
      },
      "source": [
        "no_ent_test = []\n",
        "for i, doc in tqdm(enumerate((test_docs))):\n",
        "    plain_text=''\n",
        "    start_point=0\n",
        "    for ent in doc.ents:\n",
        "        plain_text = plain_text+test_df.iloc[i]['review'][start_point : ent.start_char]+' '+ent.label_+' '\n",
        "        start_point = ent.end_char   \n",
        "    no_ent_test.append(plain_text)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e5759c479e94b8eb53c8b9f34535ad1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT83Ixny0VoA"
      },
      "source": [
        "# adding column\n",
        "train_df['no_ent'] = no_ent_train\n",
        "test_df['no_ent']  = no_ent_test"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0UFZAE1p8OJn",
        "outputId": "70f31e58-5f23-4175-fd9b-1b89aae0f1ff"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_positive</th>\n",
              "      <th>review</th>\n",
              "      <th>review_processed</th>\n",
              "      <th>no_ent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A formulaic story with all the tired cliches. ...</td>\n",
              "      <td>formula stori tire clich . shock horribl scr...</td>\n",
              "      <td>A formulaic story with all the tired cliches. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>This is both an entertaining and a touching ve...</td>\n",
              "      <td>entertain touch version classic tale , also ...</td>\n",
              "      <td>This is both an entertaining and a touching ve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Corey Haim is never going to be known as one o...</td>\n",
              "      <td>corey haim never go known one great actor ti...</td>\n",
              "      <td>PERSON  is never going to be known as  CARDIN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>If you believe that any given war movie can ma...</td>\n",
              "      <td>believ given war movi make realli feel war ,...</td>\n",
              "      <td>If you believe that any given war movie can ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Carla Gugino literally melts the screen in thi...</td>\n",
              "      <td>carla gugino liter melt screen crime caper ....</td>\n",
              "      <td>PERSON  literally melts the screen in this cr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_positive  ...                                             no_ent\n",
              "0            0  ...  A formulaic story with all the tired cliches. ...\n",
              "1            1  ...  This is both an entertaining and a touching ve...\n",
              "2            0  ...   PERSON  is never going to be known as  CARDIN...\n",
              "3            1  ...  If you believe that any given war movie can ma...\n",
              "4            1  ...   PERSON  literally melts the screen in this cr...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiLN7Hyb0VrG",
        "outputId": "ad5a63da-d301-41c0-b8ad-5d4f036859f6"
      },
      "source": [
        "# Logistic regression classificator train\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "model.fit(train_df['no_ent'], train_df['is_positive'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83LLoQT55Uy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b455603-fc60-4570-af7e-db96477d1ab3"
      },
      "source": [
        "# Evaluating\n",
        "eval_model(model, test_df)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 88.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1_s4Id6hajH"
      },
      "source": [
        "Обучим нейронную сеть в качестве модели классификации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0olXaXk5U7G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3cadac49-87c6-477f-ac6e-1e7988b74287"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalMaxPooling1D, Dropout\n",
        "from collections import Counter\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp-8Etkei1ne",
        "outputId": "504a0d83-9f40-43b6-a0dd-ed695db8496e"
      },
      "source": [
        "\n",
        "# Пронумеруем слова и конвертируем данные в array\n",
        "words_counter = Counter((word for text in train_df.review for word in text.lower().split()))\n",
        "\n",
        "word2idx = {\n",
        "    '': 0,\n",
        "    '<unk>': 1\n",
        "}\n",
        "for word, count in words_counter.most_common():\n",
        "    if count < 10:\n",
        "        break\n",
        "        \n",
        "    word2idx[word] = len(word2idx)\n",
        "    \n",
        "print('Words count', len(word2idx))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words count 26783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YI8ZKlth35j"
      },
      "source": [
        "def convert(texts, word2idx, max_text_len):\n",
        "    data = np.zeros((len(texts), max_text_len), dtype=np.int)\n",
        "    \n",
        "    for inx, text in enumerate(texts):\n",
        "        result = []\n",
        "        for word in text.split():\n",
        "            if word in word2idx:\n",
        "                result.append(word2idx[word])\n",
        "        padding = [0]*(max_text_len - len(result))\n",
        "        data[inx] = np.array(padding + result[-max_text_len:], dtype=np.int)\n",
        "    return data\n",
        "\n",
        "X_train = convert(train_df.review, word2idx, 1000)\n",
        "X_test = convert(test_df.review, word2idx, 1000)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNDhnGOgjjhV",
        "outputId": "c5e8d1f1-0218-4b5a-be79-321df0b70a7c"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,    27,  2173,    14],\n",
              "       [    0,     0,     0, ...,    43,     2,  3361],\n",
              "       [    0,     0,     0, ...,    86,  1326,   106],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,    12,     7, 17818],\n",
              "       [    0,     0,     0, ...,    73,    27,  3112],\n",
              "       [    0,     0,     0, ...,    28,    10, 23594]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykPyTxfP0Vtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c602dbc4-f177-4593-bbff-dae3bba9ceaf"
      },
      "source": [
        "dim = int(len(word2idx)**(1/2))\n",
        "\n",
        "# Используем сверточную нейронную сеть с binary_crossentropy, т.к. это бинарная классификация\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(word2idx), output_dim=dim, input_shape=(X_train.shape[1],)),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(units=10, activation='relu'),\n",
        "    Dense(units=10, activation='relu'),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1000, 163)         4365629   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 163)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1640      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 4,367,390\n",
            "Trainable params: 4,367,390\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zElXgjfAh2RJ",
        "outputId": "a59f597c-96f7-42ad-9af1-8bc79f4ba668"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(X_train, train_df.is_positive, batch_size=128, epochs=5, \n",
        "          validation_data=(X_test, test_df.is_positive), callbacks=[callback])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "196/196 [==============================] - 40s 199ms/step - loss: 0.6103 - accuracy: 0.6858 - val_loss: 0.4349 - val_accuracy: 0.8506\n",
            "Epoch 2/5\n",
            "196/196 [==============================] - 39s 201ms/step - loss: 0.2911 - accuracy: 0.8928 - val_loss: 0.2827 - val_accuracy: 0.8826\n",
            "Epoch 3/5\n",
            "196/196 [==============================] - 39s 199ms/step - loss: 0.1558 - accuracy: 0.9464 - val_loss: 0.2786 - val_accuracy: 0.8843\n",
            "Epoch 4/5\n",
            "196/196 [==============================] - 39s 199ms/step - loss: 0.0760 - accuracy: 0.9810 - val_loss: 0.3036 - val_accuracy: 0.8808\n",
            "Epoch 5/5\n",
            "196/196 [==============================] - 39s 199ms/step - loss: 0.0319 - accuracy: 0.9945 - val_loss: 0.3392 - val_accuracy: 0.8802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f43d29cdf10>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ5SxI2jkZRl",
        "outputId": "805af18e-b265-4ab7-fde5-6e0014263619"
      },
      "source": [
        "# accuracy логистической регресси = 88.3% несколько выше, чем в модели простой нейронной сети\n",
        "model.evaluate(X_test, test_df.is_positive)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 5s 6ms/step - loss: 0.3392 - accuracy: 0.8802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3392295241355896, 0.8801599740982056]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2Z5dcdtnAj6"
      },
      "source": [
        "# Обучим модель на обработанном лемматизированном столбце\n",
        "X_train = convert(train_df.review_processed, word2idx, 1000)\n",
        "X_test = convert(test_df.review_processed, word2idx, 1000)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7QvKaaKnAmz",
        "outputId": "9274c8a5-a567-4393-b28b-718205e22667"
      },
      "source": [
        "model.fit(X_train, train_df.is_positive, batch_size=128, epochs=5, \n",
        "          validation_data=(X_test, test_df.is_positive), callbacks=[callback])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "196/196 [==============================] - 38s 196ms/step - loss: 0.3114 - accuracy: 0.8686 - val_loss: 0.3601 - val_accuracy: 0.8437\n",
            "Epoch 2/5\n",
            "196/196 [==============================] - 38s 196ms/step - loss: 0.1770 - accuracy: 0.9363 - val_loss: 0.3942 - val_accuracy: 0.8389\n",
            "Epoch 3/5\n",
            "196/196 [==============================] - 39s 197ms/step - loss: 0.1150 - accuracy: 0.9648 - val_loss: 0.4249 - val_accuracy: 0.8390\n",
            "Epoch 4/5\n",
            "196/196 [==============================] - 39s 197ms/step - loss: 0.0694 - accuracy: 0.9832 - val_loss: 0.4763 - val_accuracy: 0.8326\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f43ccfab190>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5Uagz_rnApY",
        "outputId": "280bb9b3-499f-4646-be00-551920565885"
      },
      "source": [
        "# accuracy получилось даже ниже, чем при обучении модели на исходных отзывах\n",
        "model.evaluate(X_test, test_df.is_positive)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 5s 7ms/step - loss: 0.3601 - accuracy: 0.8437\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36012032628059387, 0.843720018863678]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFGhgs2KnAr6"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    }
  ]
}